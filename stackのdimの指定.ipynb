{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stackのdimの指定.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNBvmWP3rM98CeTEInGZSiu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perfectpanda-works/machine-learning/blob/master/stack%E3%81%AEdim%E3%81%AE%E6%8C%87%E5%AE%9A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMAyHj1VHwF6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "943196b2-ef80-4ee6-fde6-fc9f77aa4456"
      },
      "source": [
        "import torch\n",
        "\n",
        "#2×3の行列をテンソルとして準備\n",
        "x = torch.randn(2, 3)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7329, -1.1706, -0.3256],\n",
              "        [-0.3038,  1.0603,  1.0140]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFu0Izd2IuRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#リストを作成します。\n",
        "x_list = []\n",
        "x_list.append(x)\n",
        "x_list.append(x)\n",
        "x_list.append(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVzkDzOVI4hn",
        "colab_type": "text"
      },
      "source": [
        "全てのテンソルが同じサイズである必要があります。\n",
        "今回はすべて同じテンソルの複製なのでOK\n",
        "\n",
        "デフォルトでdim=0の設定。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK_xbB8iIyIx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "186690f6-c85e-4b5c-f876-18dc310f6ed1"
      },
      "source": [
        "print(torch.stack(x_list))\n",
        "torch.stack(x_list).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.7329, -1.1706, -0.3256],\n",
            "         [-0.3038,  1.0603,  1.0140]],\n",
            "\n",
            "        [[ 0.7329, -1.1706, -0.3256],\n",
            "         [-0.3038,  1.0603,  1.0140]],\n",
            "\n",
            "        [[ 0.7329, -1.1706, -0.3256],\n",
            "         [-0.3038,  1.0603,  1.0140]]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSxcTyN1I0f2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "591bd318-dc2b-44af-d57b-c23f8d79576e"
      },
      "source": [
        "print(torch.stack(x_list, dim=1))\n",
        "torch.stack(x_list, dim=1).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.7329, -1.1706, -0.3256],\n",
            "         [ 0.7329, -1.1706, -0.3256],\n",
            "         [ 0.7329, -1.1706, -0.3256]],\n",
            "\n",
            "        [[-0.3038,  1.0603,  1.0140],\n",
            "         [-0.3038,  1.0603,  1.0140],\n",
            "         [-0.3038,  1.0603,  1.0140]]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsdzS4AxJX8K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "9b61c23e-2560-4e7a-8ac1-5a1538883ed7"
      },
      "source": [
        "print(torch.stack(x_list, dim=2))\n",
        "torch.stack(x_list, dim=2).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.7329,  0.7329,  0.7329],\n",
            "         [-1.1706, -1.1706, -1.1706],\n",
            "         [-0.3256, -0.3256, -0.3256]],\n",
            "\n",
            "        [[-0.3038, -0.3038, -0.3038],\n",
            "         [ 1.0603,  1.0603,  1.0603],\n",
            "         [ 1.0140,  1.0140,  1.0140]]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geP239oIT4Um",
        "colab_type": "text"
      },
      "source": [
        "RGB画像の３チャンネルデータを想定した場合\n",
        "\n",
        "一般的なカラー画像では、赤(R)のみを0～255で表現する画像、緑(G)のみを0～255で表現する画像、青(B)のみを0～255で表現する画像の３枚（３チャンネル）の画像をひとつにしてカラー画像を表現しています。(透明情報のアルファが加わって4チャンネルとなる場合もあります。）\n",
        "\n",
        "PyTorchのテンソルでこのカラー画像１枚を表現すると、次のようなテンソルのサイズになります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwhcYKFGJy_a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "3e2483ae-cb77-4cc5-c193-8638f34a286f"
      },
      "source": [
        "rgb = torch.randn(3, 2, 3)\n",
        "rgb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.0691,  0.0893, -0.9815],\n",
              "         [-0.6828, -1.6071,  0.4074]],\n",
              "\n",
              "        [[ 1.1217,  1.9044,  0.1318],\n",
              "         [ 0.0065,  1.7577, -0.4926]],\n",
              "\n",
              "        [[ 0.2009,  0.2247, -0.6303],\n",
              "         [-1.0737,  0.1366, -1.2880]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAGEZNRgUIdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#リストを作成します。\n",
        "rgb_list = []\n",
        "rgb_list.append(rgb)\n",
        "rgb_list.append(rgb)\n",
        "rgb_list.append(rgb)\n",
        "rgb_list.append(rgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0jClKcKUQ0J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "9dcb20df-3a0b-467b-e522-5b582d6a6f37"
      },
      "source": [
        "print(torch.stack(rgb_list))\n",
        "torch.stack(rgb_list).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[ 1.0691,  0.0893, -0.9815],\n",
            "          [-0.6828, -1.6071,  0.4074]],\n",
            "\n",
            "         [[ 1.1217,  1.9044,  0.1318],\n",
            "          [ 0.0065,  1.7577, -0.4926]],\n",
            "\n",
            "         [[ 0.2009,  0.2247, -0.6303],\n",
            "          [-1.0737,  0.1366, -1.2880]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0691,  0.0893, -0.9815],\n",
            "          [-0.6828, -1.6071,  0.4074]],\n",
            "\n",
            "         [[ 1.1217,  1.9044,  0.1318],\n",
            "          [ 0.0065,  1.7577, -0.4926]],\n",
            "\n",
            "         [[ 0.2009,  0.2247, -0.6303],\n",
            "          [-1.0737,  0.1366, -1.2880]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0691,  0.0893, -0.9815],\n",
            "          [-0.6828, -1.6071,  0.4074]],\n",
            "\n",
            "         [[ 1.1217,  1.9044,  0.1318],\n",
            "          [ 0.0065,  1.7577, -0.4926]],\n",
            "\n",
            "         [[ 0.2009,  0.2247, -0.6303],\n",
            "          [-1.0737,  0.1366, -1.2880]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0691,  0.0893, -0.9815],\n",
            "          [-0.6828, -1.6071,  0.4074]],\n",
            "\n",
            "         [[ 1.1217,  1.9044,  0.1318],\n",
            "          [ 0.0065,  1.7577, -0.4926]],\n",
            "\n",
            "         [[ 0.2009,  0.2247, -0.6303],\n",
            "          [-1.0737,  0.1366, -1.2880]]]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}