{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LEARNING PYTORCH WITH EXAMPLES6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNuMqzpDd3gjiANTWTp9azF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perfectpanda-works/machine-learning/blob/master/LEARNING_PYTORCH_WITH_EXAMPLES6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkGgtjU8WefQ",
        "colab_type": "text"
      },
      "source": [
        "#nnモジュールのカスタマイズ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJG_50jHw-QF",
        "colab_type": "text"
      },
      "source": [
        "既存のモジュールのシーケンスよりも複雑なモデルを指定したい場合があります。\n",
        "\n",
        "これらの場合、nn.Moduleをサブクラス化し、入力テンソルを受け取り、他のモジュールまたはTensorの他のautograd操作を使用して出力テンソルを生成する転送を定義することにより、独自のモジュールを定義できます。\n",
        "\n",
        "これで、チュートリアルなどでよく見るクラスでのネットワークの定義の形になります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRXIorMPxWx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8aeea944-b37a-4362-9623-ce5d12dd3c16"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb7YcmRmxeFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TwoLayerNet(torch.nn.Module):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        \"\"\"\n",
        "        コンストラクタ\n",
        "        \"\"\"\n",
        "        super(TwoLayerNet, self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(D_in, H)\n",
        "        self.linear2 = torch.nn.Linear(H, D_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        順伝播の定義。xが入力するテンソル。\n",
        "        \"\"\"\n",
        "        h_relu = self.linear1(x).clamp(min=0)\n",
        "        y_pred = self.linear2(h_relu)\n",
        "        return y_pred"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrXVwgWywtHM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f849a2ad-c913-4e1f-b2c0-b8d7b65b3929"
      },
      "source": [
        "# N  　：バッチサイズ\n",
        "# D_in ：入力次元数\n",
        "# H　　：隠れ層の次元数\n",
        "# D_out：出力次元数\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# ランダムな入力データと出力データの作成\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "# クラスとして定義したネットワークをインスタンス化する\n",
        "model = TwoLayerNet(D_in, H, D_out)\n",
        "\n",
        "# 誤差関数：平均二乗誤差\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "# 最適化手法：勾配降下法\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
        "for t in range(500):\n",
        "    # ①順伝播\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # ②誤差の計算\n",
        "    loss = criterion(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # ③逆伝播をして、重みの更新を行う。\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 2.448106288909912\n",
            "199 0.029703807085752487\n",
            "299 0.0006881364388391376\n",
            "399 2.110017703671474e-05\n",
            "499 7.303991083063011e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZgUp4sxh4l8",
        "colab_type": "text"
      },
      "source": [
        "#制御と重みの共有について"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgfWetcZVs-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c8ec88fa-0509-47f0-b0d5-65bed456aee2"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import random\n",
        "import torch\n",
        "\n",
        "class DynamicNet(torch.nn.Module):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        \"\"\"\n",
        "        コンストラクタ：「middle_linear」を追加\n",
        "        \"\"\"\n",
        "        super(DynamicNet, self).__init__()\n",
        "        self.input_linear = torch.nn.Linear(D_in, H)\n",
        "        self.middle_linear = torch.nn.Linear(H, H)\n",
        "        self.output_linear = torch.nn.Linear(H, D_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        順伝播の「middle_layer」を0〜3回forループで繰り返します。\n",
        "        「middle_layer」をループ回数使い回しています。\n",
        "        \n",
        "        順伝播を定義するときには、Pythonのループや制御文を利用することができます。\n",
        "        \n",
        "        ここでは、計算グラフを定義するときに同じモジュールを何度も再利用しても大丈夫なことを示しています。\n",
        "        これはLuaTorch(昔のPyTorch)からの改善点で、昔は各モジュールは１回しか使えませんでした。\n",
        "        \"\"\"\n",
        "        h_relu = self.input_linear(x).clamp(min=0)\n",
        "        for _ in range(random.randint(0, 3)):\n",
        "            h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
        "        y_pred = self.output_linear(h_relu)\n",
        "        return y_pred\n",
        "\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "model = DynamicNet(D_in, H, D_out)\n",
        "\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
        "for t in range(500):\n",
        "    # 順伝播\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # 損失の計算\n",
        "    loss = criterion(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # 最適化と重みの更新\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 24.734758377075195\n",
            "199 3.7124757766723633\n",
            "299 4.8652119636535645\n",
            "399 1.488918662071228\n",
            "499 1.2936948537826538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zDpvWw4h6gV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}